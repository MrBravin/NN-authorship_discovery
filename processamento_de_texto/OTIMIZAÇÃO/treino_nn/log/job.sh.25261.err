[I 2025-09-23 09:31:38,973] A new study created in memory with name: no-name-0fd914c3-aa31-4f46-89f6-83ca14e30563
  0%|          | 0/30 [00:00<?, ?it/s]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                        0%|          | 0/30 [01:25<?, ?it/s]Best trial: 0. Best value: 0.921856:   0%|          | 0/30 [01:25<?, ?it/s]Best trial: 0. Best value: 0.921856:   3%|▎         | 1/30 [01:25<41:06, 85.05s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 0. Best value: 0.921856:   3%|▎         | 1/30 [01:49<41:06, 85.05s/it]Best trial: 0. Best value: 0.921856:   3%|▎         | 1/30 [01:49<41:06, 85.05s/it]Best trial: 0. Best value: 0.921856:   7%|▋         | 2/30 [01:49<22:57, 49.19s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 0. Best value: 0.921856:   7%|▋         | 2/30 [02:06<22:57, 49.19s/it]Best trial: 2. Best value: 0.944296:   7%|▋         | 2/30 [02:06<22:57, 49.19s/it]Best trial: 2. Best value: 0.944296:  10%|█         | 3/30 [02:06<15:32, 34.53s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.944296:  10%|█         | 3/30 [02:23<15:32, 34.53s/it]Best trial: 2. Best value: 0.944296:  10%|█         | 3/30 [02:23<15:32, 34.53s/it]Best trial: 2. Best value: 0.944296:  13%|█▎        | 4/30 [02:23<11:57, 27.60s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.944296:  13%|█▎        | 4/30 [02:41<11:57, 27.60s/it]Best trial: 2. Best value: 0.944296:  13%|█▎        | 4/30 [02:41<11:57, 27.60s/it]Best trial: 2. Best value: 0.944296:  17%|█▋        | 5/30 [02:41<10:03, 24.14s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.944296:  17%|█▋        | 5/30 [02:57<10:03, 24.14s/it]Best trial: 2. Best value: 0.944296:  17%|█▋        | 5/30 [02:57<10:03, 24.14s/it]Best trial: 2. Best value: 0.944296:  20%|██        | 6/30 [02:57<08:33, 21.41s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.944296:  20%|██        | 6/30 [03:22<08:33, 21.41s/it]Best trial: 2. Best value: 0.944296:  20%|██        | 6/30 [03:22<08:33, 21.41s/it]Best trial: 2. Best value: 0.944296:  23%|██▎       | 7/30 [03:22<08:40, 22.64s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.944296:  23%|██▎       | 7/30 [03:36<08:40, 22.64s/it]Best trial: 2. Best value: 0.944296:  23%|██▎       | 7/30 [03:36<08:40, 22.64s/it]Best trial: 2. Best value: 0.944296:  27%|██▋       | 8/30 [03:36<07:16, 19.84s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.944296:  27%|██▋       | 8/30 [04:22<07:16, 19.84s/it]Best trial: 8. Best value: 0.945829:  27%|██▋       | 8/30 [04:22<07:16, 19.84s/it]Best trial: 8. Best value: 0.945829:  30%|███       | 9/30 [04:22<09:51, 28.15s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 8. Best value: 0.945829:  30%|███       | 9/30 [04:38<09:51, 28.15s/it]Best trial: 8. Best value: 0.945829:  30%|███       | 9/30 [04:38<09:51, 28.15s/it]Best trial: 8. Best value: 0.945829:  33%|███▎      | 10/30 [04:38<08:06, 24.32s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                    Best trial: 8. Best value: 0.945829:  33%|███▎      | 10/30 [05:16<08:06, 24.32s/it]Best trial: 8. Best value: 0.945829:  33%|███▎      | 10/30 [05:16<08:06, 24.32s/it]Best trial: 8. Best value: 0.945829:  37%|███▋      | 11/30 [05:16<09:01, 28.51s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                    Best trial: 8. Best value: 0.945829:  37%|███▋      | 11/30 [06:00<09:01, 28.51s/it]Best trial: 11. Best value: 0.9506:  37%|███▋      | 11/30 [06:00<09:01, 28.51s/it] Best trial: 11. Best value: 0.9506:  40%|████      | 12/30 [06:00<09:56, 33.16s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 11. Best value: 0.9506:  40%|████      | 12/30 [06:41<09:56, 33.16s/it]Best trial: 11. Best value: 0.9506:  40%|████      | 12/30 [06:41<09:56, 33.16s/it]Best trial: 11. Best value: 0.9506:  43%|████▎     | 13/30 [06:41<10:06, 35.67s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 11. Best value: 0.9506:  43%|████▎     | 13/30 [07:28<10:06, 35.67s/it]Best trial: 13. Best value: 0.951711:  43%|████▎     | 13/30 [07:28<10:06, 35.67s/it]Best trial: 13. Best value: 0.951711:  47%|████▋     | 14/30 [07:28<10:25, 39.12s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 13. Best value: 0.951711:  47%|████▋     | 14/30 [08:13<10:25, 39.12s/it]Best trial: 14. Best value: 0.951855:  47%|████▋     | 14/30 [08:13<10:25, 39.12s/it]Best trial: 14. Best value: 0.951855:  50%|█████     | 15/30 [08:13<10:12, 40.84s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 14. Best value: 0.951855:  50%|█████     | 15/30 [08:35<10:12, 40.84s/it]Best trial: 15. Best value: 0.954235:  50%|█████     | 15/30 [08:35<10:12, 40.84s/it]Best trial: 15. Best value: 0.954235:  53%|█████▎    | 16/30 [08:35<08:10, 35.07s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  53%|█████▎    | 16/30 [08:57<08:10, 35.07s/it]Best trial: 15. Best value: 0.954235:  53%|█████▎    | 16/30 [08:57<08:10, 35.07s/it]Best trial: 15. Best value: 0.954235:  57%|█████▋    | 17/30 [08:57<06:45, 31.23s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  57%|█████▋    | 17/30 [09:12<06:45, 31.23s/it]Best trial: 15. Best value: 0.954235:  57%|█████▋    | 17/30 [09:12<06:45, 31.23s/it]Best trial: 15. Best value: 0.954235:  60%|██████    | 18/30 [09:12<05:15, 26.28s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  60%|██████    | 18/30 [09:31<05:15, 26.28s/it]Best trial: 15. Best value: 0.954235:  60%|██████    | 18/30 [09:31<05:15, 26.28s/it]Best trial: 15. Best value: 0.954235:  63%|██████▎   | 19/30 [09:31<04:24, 24.04s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  63%|██████▎   | 19/30 [09:42<04:24, 24.04s/it]Best trial: 15. Best value: 0.954235:  63%|██████▎   | 19/30 [09:42<04:24, 24.04s/it]Best trial: 15. Best value: 0.954235:  67%|██████▋   | 20/30 [09:42<03:22, 20.29s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  67%|██████▋   | 20/30 [10:06<03:22, 20.29s/it]Best trial: 15. Best value: 0.954235:  67%|██████▋   | 20/30 [10:06<03:22, 20.29s/it]Best trial: 15. Best value: 0.954235:  70%|███████   | 21/30 [10:06<03:12, 21.38s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  70%|███████   | 21/30 [10:51<03:12, 21.38s/it]Best trial: 15. Best value: 0.954235:  70%|███████   | 21/30 [10:51<03:12, 21.38s/it]Best trial: 15. Best value: 0.954235:  73%|███████▎  | 22/30 [10:51<03:48, 28.55s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  73%|███████▎  | 22/30 [11:37<03:48, 28.55s/it]Best trial: 15. Best value: 0.954235:  73%|███████▎  | 22/30 [11:37<03:48, 28.55s/it]Best trial: 15. Best value: 0.954235:  77%|███████▋  | 23/30 [11:37<03:56, 33.72s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  77%|███████▋  | 23/30 [11:59<03:56, 33.72s/it]Best trial: 15. Best value: 0.954235:  77%|███████▋  | 23/30 [11:59<03:56, 33.72s/it]Best trial: 15. Best value: 0.954235:  80%|████████  | 24/30 [11:59<03:01, 30.24s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  80%|████████  | 24/30 [12:16<03:01, 30.24s/it]Best trial: 15. Best value: 0.954235:  80%|████████  | 24/30 [12:16<03:01, 30.24s/it]Best trial: 15. Best value: 0.954235:  83%|████████▎ | 25/30 [12:16<02:10, 26.19s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  83%|████████▎ | 25/30 [12:45<02:10, 26.19s/it]Best trial: 15. Best value: 0.954235:  83%|████████▎ | 25/30 [12:45<02:10, 26.19s/it]Best trial: 15. Best value: 0.954235:  87%|████████▋ | 26/30 [12:45<01:48, 27.01s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  87%|████████▋ | 26/30 [12:59<01:48, 27.01s/it]Best trial: 15. Best value: 0.954235:  87%|████████▋ | 26/30 [12:59<01:48, 27.01s/it]Best trial: 15. Best value: 0.954235:  90%|█████████ | 27/30 [12:59<01:09, 23.01s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  90%|█████████ | 27/30 [13:18<01:09, 23.01s/it]Best trial: 15. Best value: 0.954235:  90%|█████████ | 27/30 [13:18<01:09, 23.01s/it]Best trial: 15. Best value: 0.954235:  93%|█████████▎| 28/30 [13:18<00:43, 21.80s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  93%|█████████▎| 28/30 [13:34<00:43, 21.80s/it]Best trial: 15. Best value: 0.954235:  93%|█████████▎| 28/30 [13:34<00:43, 21.80s/it]Best trial: 15. Best value: 0.954235:  97%|█████████▋| 29/30 [13:34<00:20, 20.17s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 15. Best value: 0.954235:  97%|█████████▋| 29/30 [14:02<00:20, 20.17s/it]Best trial: 15. Best value: 0.954235:  97%|█████████▋| 29/30 [14:02<00:20, 20.17s/it]Best trial: 15. Best value: 0.954235: 100%|██████████| 30/30 [14:02<00:00, 22.60s/it]Best trial: 15. Best value: 0.954235: 100%|██████████| 30/30 [14:02<00:00, 28.09s/it]
/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
[I 2025-09-23 09:46:59,327] A new study created in memory with name: no-name-c33e21b0-7aba-42da-be5c-b1e08666c053
  0%|          | 0/30 [00:00<?, ?it/s]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                        0%|          | 0/30 [00:32<?, ?it/s]Best trial: 0. Best value: 0.923586:   0%|          | 0/30 [00:32<?, ?it/s]Best trial: 0. Best value: 0.923586:   3%|▎         | 1/30 [00:32<15:46, 32.64s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 0. Best value: 0.923586:   3%|▎         | 1/30 [00:47<15:46, 32.64s/it]Best trial: 0. Best value: 0.923586:   3%|▎         | 1/30 [00:47<15:46, 32.64s/it]Best trial: 0. Best value: 0.923586:   7%|▋         | 2/30 [00:47<10:21, 22.20s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 0. Best value: 0.923586:   7%|▋         | 2/30 [01:06<10:21, 22.20s/it]Best trial: 2. Best value: 0.934874:   7%|▋         | 2/30 [01:06<10:21, 22.20s/it]Best trial: 2. Best value: 0.934874:  10%|█         | 3/30 [01:06<09:25, 20.95s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.934874:  10%|█         | 3/30 [01:41<09:25, 20.95s/it]Best trial: 2. Best value: 0.934874:  10%|█         | 3/30 [01:41<09:25, 20.95s/it]Best trial: 2. Best value: 0.934874:  13%|█▎        | 4/30 [01:41<11:19, 26.13s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 2. Best value: 0.934874:  13%|█▎        | 4/30 [02:05<11:19, 26.13s/it]Best trial: 4. Best value: 0.936424:  13%|█▎        | 4/30 [02:05<11:19, 26.13s/it]Best trial: 4. Best value: 0.936424:  17%|█▋        | 5/30 [02:05<10:40, 25.62s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 4. Best value: 0.936424:  17%|█▋        | 5/30 [02:34<10:40, 25.62s/it]Best trial: 4. Best value: 0.936424:  17%|█▋        | 5/30 [02:34<10:40, 25.62s/it]Best trial: 4. Best value: 0.936424:  20%|██        | 6/30 [02:34<10:43, 26.81s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 4. Best value: 0.936424:  20%|██        | 6/30 [02:51<10:43, 26.81s/it]Best trial: 4. Best value: 0.936424:  20%|██        | 6/30 [02:51<10:43, 26.81s/it]Best trial: 4. Best value: 0.936424:  23%|██▎       | 7/30 [02:51<08:58, 23.40s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 4. Best value: 0.936424:  23%|██▎       | 7/30 [03:19<08:58, 23.40s/it]Best trial: 7. Best value: 0.94373:  23%|██▎       | 7/30 [03:19<08:58, 23.40s/it] Best trial: 7. Best value: 0.94373:  27%|██▋       | 8/30 [03:19<09:10, 25.01s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                  Best trial: 7. Best value: 0.94373:  27%|██▋       | 8/30 [04:21<09:10, 25.01s/it]Best trial: 7. Best value: 0.94373:  27%|██▋       | 8/30 [04:21<09:10, 25.01s/it]Best trial: 7. Best value: 0.94373:  30%|███       | 9/30 [04:21<12:49, 36.63s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                  Best trial: 7. Best value: 0.94373:  30%|███       | 9/30 [04:47<12:49, 36.63s/it]Best trial: 7. Best value: 0.94373:  30%|███       | 9/30 [04:47<12:49, 36.63s/it]Best trial: 7. Best value: 0.94373:  33%|███▎      | 10/30 [04:47<11:01, 33.09s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 7. Best value: 0.94373:  33%|███▎      | 10/30 [05:05<11:01, 33.09s/it]Best trial: 7. Best value: 0.94373:  33%|███▎      | 10/30 [05:05<11:01, 33.09s/it]Best trial: 7. Best value: 0.94373:  37%|███▋      | 11/30 [05:05<09:05, 28.69s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 7. Best value: 0.94373:  37%|███▋      | 11/30 [06:16<09:05, 28.69s/it]Best trial: 7. Best value: 0.94373:  37%|███▋      | 11/30 [06:16<09:05, 28.69s/it]Best trial: 7. Best value: 0.94373:  40%|████      | 12/30 [06:16<12:28, 41.58s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                   Best trial: 7. Best value: 0.94373:  40%|████      | 12/30 [07:06<12:28, 41.58s/it]Best trial: 12. Best value: 0.943855:  40%|████      | 12/30 [07:06<12:28, 41.58s/it]Best trial: 12. Best value: 0.943855:  43%|████▎     | 13/30 [07:06<12:27, 43.99s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 12. Best value: 0.943855:  43%|████▎     | 13/30 [07:54<12:27, 43.99s/it]Best trial: 12. Best value: 0.943855:  43%|████▎     | 13/30 [07:54<12:27, 43.99s/it]Best trial: 12. Best value: 0.943855:  47%|████▋     | 14/30 [07:54<12:01, 45.11s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 12. Best value: 0.943855:  47%|████▋     | 14/30 [08:52<12:01, 45.11s/it]Best trial: 14. Best value: 0.94754:  47%|████▋     | 14/30 [08:52<12:01, 45.11s/it] Best trial: 14. Best value: 0.94754:  50%|█████     | 15/30 [08:52<12:14, 48.99s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                    Best trial: 14. Best value: 0.94754:  50%|█████     | 15/30 [09:37<12:14, 48.99s/it]Best trial: 14. Best value: 0.94754:  50%|█████     | 15/30 [09:37<12:14, 48.99s/it]Best trial: 14. Best value: 0.94754:  53%|█████▎    | 16/30 [09:37<11:10, 47.92s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                    Best trial: 14. Best value: 0.94754:  53%|█████▎    | 16/30 [10:28<11:10, 47.92s/it]Best trial: 14. Best value: 0.94754:  53%|█████▎    | 16/30 [10:28<11:10, 47.92s/it]Best trial: 14. Best value: 0.94754:  57%|█████▋    | 17/30 [10:28<10:33, 48.73s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                    Best trial: 14. Best value: 0.94754:  57%|█████▋    | 17/30 [11:20<10:33, 48.73s/it]Best trial: 17. Best value: 0.948389:  57%|█████▋    | 17/30 [11:20<10:33, 48.73s/it]Best trial: 17. Best value: 0.948389:  60%|██████    | 18/30 [11:20<09:58, 49.86s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 17. Best value: 0.948389:  60%|██████    | 18/30 [11:53<09:58, 49.86s/it]Best trial: 18. Best value: 0.954011:  60%|██████    | 18/30 [11:53<09:58, 49.86s/it]Best trial: 18. Best value: 0.954011:  63%|██████▎   | 19/30 [11:53<08:12, 44.74s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  63%|██████▎   | 19/30 [12:12<08:12, 44.74s/it]Best trial: 18. Best value: 0.954011:  63%|██████▎   | 19/30 [12:12<08:12, 44.74s/it]Best trial: 18. Best value: 0.954011:  67%|██████▋   | 20/30 [12:12<06:11, 37.12s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  67%|██████▋   | 20/30 [12:39<06:11, 37.12s/it]Best trial: 18. Best value: 0.954011:  67%|██████▋   | 20/30 [12:39<06:11, 37.12s/it]Best trial: 18. Best value: 0.954011:  70%|███████   | 21/30 [12:39<05:06, 34.08s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  70%|███████   | 21/30 [13:15<05:06, 34.08s/it]Best trial: 18. Best value: 0.954011:  70%|███████   | 21/30 [13:15<05:06, 34.08s/it]Best trial: 18. Best value: 0.954011:  73%|███████▎  | 22/30 [13:15<04:36, 34.53s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  73%|███████▎  | 22/30 [13:46<04:36, 34.53s/it]Best trial: 18. Best value: 0.954011:  73%|███████▎  | 22/30 [13:46<04:36, 34.53s/it]Best trial: 18. Best value: 0.954011:  77%|███████▋  | 23/30 [13:46<03:54, 33.55s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  77%|███████▋  | 23/30 [14:30<03:54, 33.55s/it]Best trial: 18. Best value: 0.954011:  77%|███████▋  | 23/30 [14:30<03:54, 33.55s/it]Best trial: 18. Best value: 0.954011:  80%|████████  | 24/30 [14:30<03:39, 36.53s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  80%|████████  | 24/30 [14:59<03:39, 36.53s/it]Best trial: 18. Best value: 0.954011:  80%|████████  | 24/30 [14:59<03:39, 36.53s/it]Best trial: 18. Best value: 0.954011:  83%|████████▎ | 25/30 [14:59<02:51, 34.36s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  83%|████████▎ | 25/30 [15:35<02:51, 34.36s/it]Best trial: 18. Best value: 0.954011:  83%|████████▎ | 25/30 [15:35<02:51, 34.36s/it]Best trial: 18. Best value: 0.954011:  87%|████████▋ | 26/30 [15:35<02:19, 34.87s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  87%|████████▋ | 26/30 [16:00<02:19, 34.87s/it]Best trial: 18. Best value: 0.954011:  87%|████████▋ | 26/30 [16:00<02:19, 34.87s/it]Best trial: 18. Best value: 0.954011:  90%|█████████ | 27/30 [16:00<01:35, 31.85s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  90%|█████████ | 27/30 [16:20<01:35, 31.85s/it]Best trial: 18. Best value: 0.954011:  90%|█████████ | 27/30 [16:20<01:35, 31.85s/it]Best trial: 18. Best value: 0.954011:  93%|█████████▎| 28/30 [16:20<00:56, 28.37s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  93%|█████████▎| 28/30 [16:43<00:56, 28.37s/it]Best trial: 18. Best value: 0.954011:  93%|█████████▎| 28/30 [16:43<00:56, 28.37s/it]Best trial: 18. Best value: 0.954011:  97%|█████████▋| 29/30 [16:43<00:26, 26.85s/it]/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
                                                                                     Best trial: 18. Best value: 0.954011:  97%|█████████▋| 29/30 [17:06<00:26, 26.85s/it]Best trial: 18. Best value: 0.954011:  97%|█████████▋| 29/30 [17:06<00:26, 26.85s/it]Best trial: 18. Best value: 0.954011: 100%|██████████| 30/30 [17:06<00:00, 25.58s/it]Best trial: 18. Best value: 0.954011: 100%|██████████| 30/30 [17:06<00:00, 34.21s/it]
/home/pedro23013/tcc/t3/treino_nn/siamese_mlp_optuna.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(amp and torch.cuda.is_available()))
